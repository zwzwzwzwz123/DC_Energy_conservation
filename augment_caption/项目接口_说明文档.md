# æ•°æ®ä¸­å¿ƒèŠ‚èƒ½é¡¹ç›® - æ¥å£å¼€å‘æŒ‡å—

> ğŸ“š **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> ğŸ“… **æ›´æ–°æ—¥æœŸ**: 2025å¹´1æœˆ  
> ğŸ¯ **é€‚ç”¨èŒƒå›´**: ä¸ºæ¥æ‰‹é¡¹ç›®çš„å¼€å‘è€…æä¾›å®Œæ•´çš„æ¥å£å¼€å‘æŒ‡å—

---

## ç›®å½•

1. [é¡¹ç›®æ¶æ„æ¦‚è¿°](#1-é¡¹ç›®æ¶æ„æ¦‚è¿°)
2. [æ ¸å¿ƒæ¦‚å¿µï¼šAppContextï¼ˆctxï¼‰](#2-æ ¸å¿ƒæ¦‚å¿µappcontextctx)
3. [æ•°æ®è¯»å–æ¥å£](#3-æ•°æ®è¯»å–æ¥å£)
4. [æ•°æ®å†™å…¥æ¥å£](#4-æ•°æ®å†™å…¥æ¥å£)
5. [å…³é”®æ“ä½œä¿æŠ¤æ¥å£](#5-å…³é”®æ“ä½œä¿æŠ¤æ¥å£)
6. [çº¿ç¨‹æ§åˆ¶æ¥å£](#6-çº¿ç¨‹æ§åˆ¶æ¥å£)
7. [æ¨¡å—å¼€å‘æŒ‡å—](#7-æ¨¡å—å¼€å‘æŒ‡å—)
8. [å¼€å‘æ³¨æ„äº‹é¡¹](#8-å¼€å‘æ³¨æ„äº‹é¡¹)
9. [é™„å½•ï¼šé…ç½®æ–‡ä»¶è¯´æ˜](#9-é™„å½•é…ç½®æ–‡ä»¶è¯´æ˜)

---

## 1. é¡¹ç›®æ¶æ„æ¦‚è¿°

### 1.1 ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        main.pyï¼ˆä¸»ç¨‹åºå…¥å£ï¼‰                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   initialize_system()                      â”‚   â”‚
â”‚  â”‚  - åŠ è½½é…ç½®æ–‡ä»¶  - åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ  - åˆå§‹åŒ–InfluxDBå®¢æˆ·ç«¯  â”‚   â”‚
â”‚  â”‚  - åŠ è½½æ•°æ®ä¸­å¿ƒé…ç½®  - åˆ›å»ºæ•°æ®è¯»å†™å™¨  - åˆ›å»ºAppContext    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                    â”‚
â”‚                              â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚              ThreadPoolExecutor (3 ä¸ªå·¥ä½œçº¿ç¨‹)                â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚                                                               â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚  â”‚ é¢„æµ‹è®­ç»ƒçº¿ç¨‹     â”‚  â”‚ é¢„æµ‹æ¨ç†çº¿ç¨‹     â”‚  â”‚ ä¼˜åŒ–çº¿ç¨‹     â”‚ â”‚â”‚
â”‚  â”‚  â”‚ (prediction_    â”‚  â”‚ (prediction_    â”‚  â”‚ (optimizationâ”‚ â”‚â”‚
â”‚  â”‚  â”‚  training)      â”‚  â”‚  inference)     â”‚  â”‚  _thread)    â”‚ â”‚â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚â”‚
â”‚  â”‚  â”‚ å‘¨æœŸ: 3600s     â”‚  â”‚ å‘¨æœŸ: 300s      â”‚  â”‚ å‘¨æœŸ: 600s   â”‚ â”‚â”‚
â”‚  â”‚  â”‚ èŒè´£: è®­ç»ƒæ¨¡å‹   â”‚  â”‚ èŒè´£: æ‰§è¡Œæ¨ç†   â”‚  â”‚ èŒè´£: ä¼˜åŒ–   â”‚ â”‚â”‚
â”‚  â”‚  â”‚        ä¿å­˜æ¨¡å‹  â”‚  â”‚        å†™å…¥é¢„æµ‹  â”‚  â”‚      å†™æ§åˆ¶  â”‚ â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ä¸‰ä¸ªå·¥ä½œçº¿ç¨‹è¯¦è§£

| çº¿ç¨‹åç§° | å‡½æ•°å | ä¸»è¦èŒè´£ | é»˜è®¤å‘¨æœŸ |
|---------|--------|---------|---------|
| é¢„æµ‹è®­ç»ƒçº¿ç¨‹ | `prediction_training_thread(ctx)` | è¯»å–å†å²æ•°æ®ï¼Œè®­ç»ƒé¢„æµ‹æ¨¡å‹ï¼Œä¿å­˜æ¨¡å‹ | 3600ç§’ |
| é¢„æµ‹æ¨ç†çº¿ç¨‹ | `prediction_inference_thread(ctx)` | åŠ è½½æ¨¡å‹ï¼Œæ‰§è¡Œæ¨ç†ï¼Œå†™å…¥é¢„æµ‹ç»“æœ | 300ç§’ |
| ä¼˜åŒ–çº¿ç¨‹ | `optimization_thread(ctx)` | è¯»å–é¢„æµ‹å’ŒçŠ¶æ€æ•°æ®ï¼Œæ‰§è¡Œä¼˜åŒ–ï¼Œå†™å…¥æ§åˆ¶æŒ‡ä»¤ | 600ç§’ |

### 1.3 æ•°æ®æµå‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dc_status_data   â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   é¢„æµ‹è®­ç»ƒ/æ¨ç†   â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ prediction_data  â”‚
â”‚   (InfluxDB)     â”‚        â”‚      çº¿ç¨‹         â”‚        â”‚   (InfluxDB)     â”‚
â”‚ æ•°æ®ä¸­å¿ƒçŠ¶æ€æ•°æ®  â”‚        â”‚                  â”‚        â”‚   é¢„æµ‹ç»“æœå­˜å‚¨    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                                       â”‚
         â”‚                                                       â–¼
         â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    ä¼˜åŒ–çº¿ç¨‹       â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ optimization_dataâ”‚
                            â”‚                  â”‚        â”‚   (InfluxDB)     â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   æ§åˆ¶æŒ‡ä»¤å­˜å‚¨    â”‚
                                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. æ ¸å¿ƒæ¦‚å¿µï¼šAppContextï¼ˆctxï¼‰

### 2.1 ä»€ä¹ˆæ˜¯ AppContextï¼Ÿ

`AppContext` æ˜¯æ•´ä¸ªåº”ç”¨çš„**ä¸Šä¸‹æ–‡å¯¹è±¡**ï¼Œå°è£…äº†æ‰€æœ‰å…¨å±€çŠ¶æ€å’Œèµ„æºã€‚åœ¨æ¨¡å—å¼€å‘ä¸­ï¼Œæ‰€æœ‰çš„æ“ä½œéƒ½é€šè¿‡ `ctx` æ¥è®¿é—®ã€‚

### 2.2 AppContext å®Œæ•´ç»“æ„

```python
@dataclass
class AppContext:
    # ========== æ—¥å¿—å’Œå®¢æˆ·ç«¯ ==========
    loggers: Dict[str, logging.Logger]           # æ‰€æœ‰æ—¥å¿—å™¨
    dc_status_data_client: InfluxDBClientWrapper # æ•°æ®ä¸­å¿ƒçŠ¶æ€æ•°æ®å®¢æˆ·ç«¯ï¼ˆè¯»ï¼‰
    prediction_data_client: InfluxDBClientWrapper # é¢„æµ‹æ•°æ®å®¢æˆ·ç«¯ï¼ˆè¯»å†™ï¼‰
    optimization_data_client: InfluxDBClientWrapper # ä¼˜åŒ–æ•°æ®å®¢æˆ·ç«¯ï¼ˆå†™ï¼‰
    shutdown_event: Event                        # å…³é—­äº‹ä»¶ï¼ˆçº¿ç¨‹æ§åˆ¶ï¼‰

    # ========== é…ç½®æ–‡ä»¶ï¼ˆå…¨å±€åªè¯»ï¼‰==========
    main_config: Dict           # ä¸»é…ç½®ï¼ˆçº¿ç¨‹å‚æ•°ã€å…³é—­è¶…æ—¶ç­‰ï¼‰
    uid_config: Dict            # UIDé…ç½®ï¼ˆæ•°æ®ä¸­å¿ƒæ¶æ„å’ŒUIDæ˜ å°„ï¼‰
    models_config: Dict         # æ¨¡å‹é…ç½®ï¼ˆé¢„æµ‹æ¨¡å‹ã€ä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼‰
    modules_config: Dict        # æ¨¡å—é…ç½®ï¼ˆå„æ¨¡å—çš„è¿è¡Œå‚æ•°ï¼‰
    security_boundary_config: Dict # å®‰å…¨è¾¹ç•Œé…ç½®ï¼ˆæ§åˆ¶èŒƒå›´ã€çº¦æŸæ¡ä»¶ï¼‰
    utils_config: Dict          # å·¥å…·é…ç½®ï¼ˆæ—¥å¿—ã€InfluxDBè¿æ¥é…ç½®ï¼‰
    influxdb_read_write_config: Dict # InfluxDBè¯»å†™ç­–ç•¥é…ç½®

    # ========== è¿è¡Œæ—¶çŠ¶æ€ ==========
    critical_operation_lock: Lock = field(default_factory=Lock)
    critical_operation_count: int = 0
    datacenter: DataCenter = None    # æ•°æ®ä¸­å¿ƒå¯¹è±¡ï¼ˆå®Œæ•´å±‚æ¬¡ç»“æ„ï¼‰
    data_reader: Any = None          # æ•°æ®è¯»å–å™¨
    data_writer: Any = None          # æ•°æ®å†™å…¥å™¨
```

### 2.3 å¸¸ç”¨å±æ€§è®¿é—®ç¤ºä¾‹

```python
def your_module_function(ctx: AppContext):
    # è·å–æ—¥å¿—å™¨
    logger = ctx.loggers["prediction_training"]  # æˆ– "prediction_inference", "optimization"
    
    # è®¿é—®é…ç½®æ–‡ä»¶
    model_params = ctx.models_config.get("prediction_model", {})
    
    # ä½¿ç”¨æ•°æ®è¯»å–å™¨
    data = ctx.data_reader.read_influxdb_data("dc_status_data_client", "datacenter_latest_status")
    
    # ä½¿ç”¨æ•°æ®å†™å…¥å™¨
    ctx.data_writer.write_influxdb_data("prediction_data_client", "prediction_by_uid", data)
    
    # æ£€æŸ¥å…³é—­ä¿¡å·
    if ctx.shutdown_event.is_set():
        logger.info("æ”¶åˆ°å…³é—­ä¿¡å·")
        return
```

---

## 3. æ•°æ®è¯»å–æ¥å£

### 3.1 æ¥å£æ¦‚è¿°

æ•°æ®è¯»å–é€šè¿‡ `ctx.data_reader.read_influxdb_data()` æ–¹æ³•å®ç°ï¼Œæ”¯æŒçµæ´»çš„é…ç½®é©±åŠ¨è¯»å–ã€‚

### 3.2 æ¥å£å®šä¹‰

```python
def read_influxdb_data(
    client_key: str,      # å®¢æˆ·ç«¯é”®å
    config_key: str       # é…ç½®é¡¹é”®å
) -> Dict[str, pd.DataFrame]:
    """
    åŠŸèƒ½: æ ¹æ®å®¢æˆ·ç«¯å’Œé…ç½®ä» InfluxDB è¯»å–æ•°æ®

    å‚æ•°:
        client_key: å®¢æˆ·ç«¯é”®å
            - "dc_status_data_client": è¯»å–æ•°æ®ä¸­å¿ƒçŠ¶æ€æ•°æ®
            - "prediction_data_client": è¯»å–é¢„æµ‹ç»“æœæ•°æ®

        config_key: é…ç½®é¡¹é”®åï¼ˆå®šä¹‰åœ¨ influxdb_read_write_config.yaml ä¸­ï¼‰
            - "datacenter_latest_status": è¯»å–æ‰€æœ‰å¯è§‚æµ‹æ•°æ®
            - "critical_devices_data": è¯»å–å…³é”®è®¾å¤‡æ•°æ®
            - "specific_sensors_data": è¯»å–ç‰¹å®šæµ‹ç‚¹æ•°æ®
            - "latest_predictions": è¯»å–æœ€æ–°é¢„æµ‹ç»“æœ
            ç­‰...

    è¿”å›:
        Dict[str, pd.DataFrame]: uid -> DataFrame çš„æ˜ å°„
        æ¯ä¸ª DataFrame åŒ…å« 'timestamp' å’Œ 'value' ä¸¤åˆ—

    å¼‚å¸¸:
        ValueError: å®¢æˆ·ç«¯æˆ–é…ç½®ä¸å­˜åœ¨
    """
```

### 3.3 ä½¿ç”¨ç¤ºä¾‹

#### ç¤ºä¾‹ 1: è¯»å–æ‰€æœ‰å¯è§‚æµ‹æ•°æ®

```python
def prediction_training_thread(ctx: AppContext):
    logger = ctx.loggers["prediction_training"]

    try:
        # è¯»å–æ•°æ®ä¸­å¿ƒæ‰€æœ‰å¯è§‚æµ‹ç‚¹çš„æœ€æ–°çŠ¶æ€
        observable_data = ctx.data_reader.read_influxdb_data(
            "dc_status_data_client",      # ä½¿ç”¨çŠ¶æ€æ•°æ®å®¢æˆ·ç«¯
            "datacenter_latest_status"     # ä½¿ç”¨"è¯»å–æ‰€æœ‰å¯è§‚æµ‹æ•°æ®"é…ç½®
        )

        logger.info(f"æˆåŠŸè¯»å– {len(observable_data)} ä¸ªå¯è§‚æµ‹ç‚¹çš„æ•°æ®")

        # éå†æ•°æ®
        for uid, df in observable_data.items():
            if not df.empty:
                latest_value = df['value'].iloc[0]
                logger.debug(f"{uid}: {latest_value}")

    except Exception as e:
        logger.error(f"è¯»å–æ•°æ®å¤±è´¥: {e}")
```

#### ç¤ºä¾‹ 2: è¯»å–é¢„æµ‹ç»“æœï¼ˆä¼˜åŒ–çº¿ç¨‹ä½¿ç”¨ï¼‰

```python
def optimization_thread(ctx: AppContext):
    logger = ctx.loggers["optimization"]

    # 1. è¯»å–é¢„æµ‹ç»“æœ
    prediction_data = ctx.data_reader.read_influxdb_data(
        "prediction_data_client",    # ä½¿ç”¨é¢„æµ‹æ•°æ®å®¢æˆ·ç«¯
        "latest_predictions"          # è¯»å–æœ€æ–°é¢„æµ‹ç»“æœ
    )

    # 2. è¯»å–å½“å‰çŠ¶æ€
    current_status = ctx.data_reader.read_influxdb_data(
        "dc_status_data_client",
        "datacenter_latest_status"
    )

    # 3. åˆå¹¶æ•°æ®è¿›è¡Œä¼˜åŒ–å†³ç­–
    # ...
```

### 3.4 è¿”å›å€¼å¤„ç†

```python
# è¿”å›å€¼æ˜¯ Dict[str, pd.DataFrame]
observable_data = ctx.data_reader.read_influxdb_data(...)

# æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
if not observable_data:
    logger.warning("æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æ•°æ®")
    return

# æ£€æŸ¥æœ‰æ•ˆæ•°æ®ç‚¹æ•°é‡
valid_count = sum(1 for df in observable_data.values() if not df.empty)
logger.info(f"æœ‰æ•ˆæ•°æ®ç‚¹: {valid_count}/{len(observable_data)}")

# è·å–ç‰¹å®š uid çš„æ•°æ®
if "ac_a1_001_supply_temp" in observable_data:
    temp_df = observable_data["ac_a1_001_supply_temp"]
    if not temp_df.empty:
        # DataFrame ç»“æ„: timestamp, value
        latest_temp = temp_df['value'].iloc[0]
        latest_time = temp_df['timestamp'].iloc[0]
```

---

## 4. æ•°æ®å†™å…¥æ¥å£

### 4.1 æ¥å£æ¦‚è¿°

æ•°æ®å†™å…¥é€šè¿‡ `ctx.data_writer.write_influxdb_data()` æ–¹æ³•å®ç°ï¼Œå†…éƒ¨è‡ªåŠ¨ä½¿ç”¨ `critical_operation` ä¿æŠ¤å†™å…¥æ“ä½œã€‚

### 4.2 æ¥å£å®šä¹‰

```python
def write_influxdb_data(
    client_key: str,           # å®¢æˆ·ç«¯é”®å
    config_key: str,           # é…ç½®é¡¹é”®å
    main_data: Dict[str, Any], # ä¸»è¦æ•°æ®
    **kwargs                   # é™„åŠ å‚æ•°ï¼ˆç”¨äºæ„å»º Tag ç­‰ï¼‰
) -> bool:
    """
    åŠŸèƒ½: æ ¹æ®å®¢æˆ·ç«¯å’Œé…ç½®å‘ InfluxDB å†™å…¥æ•°æ®

    å‚æ•°:
        client_key: å®¢æˆ·ç«¯é”®å
            - "prediction_data_client": å†™å…¥é¢„æµ‹ç»“æœ
            - "optimization_data_client": å†™å…¥ä¼˜åŒ–æ§åˆ¶æŒ‡ä»¤

        config_key: å†™å…¥é…ç½®é¡¹ï¼ˆå®šä¹‰åœ¨ influxdb_read_write_config.yaml çš„ write éƒ¨åˆ†ï¼‰
            - "prediction_by_uid": æŒ‰æµ‹ç‚¹åˆ†ç¦»å­˜å‚¨é¢„æµ‹æ•°æ®
            - "prediction_unified": ç»Ÿä¸€æ ¼å¼å­˜å‚¨é¢„æµ‹æ•°æ®
            - "optimization_by_uid": æŒ‰æµ‹ç‚¹åˆ†ç¦»å­˜å‚¨ä¼˜åŒ–æŒ‡ä»¤
            - "optimization_unified": ç»Ÿä¸€æ ¼å¼å­˜å‚¨ä¼˜åŒ–æŒ‡ä»¤

        main_data: ä¸»è¦æ•°æ®å­—å…¸
            æ ¼å¼: {uid: value} æˆ– {uid: json_string}

        **kwargs: é™„åŠ å‚æ•°ï¼Œç”¨äºå¡«å……é…ç½®ä¸­çš„æ¨¡æ¿å˜é‡
            ä¾‹å¦‚: horizon="15mins", is_auto_execute=True

    è¿”å›:
        bool: å†™å…¥æ˜¯å¦æˆåŠŸ
    """
```

### 4.3 ä½¿ç”¨ç¤ºä¾‹

#### ç¤ºä¾‹ 1: å†™å…¥é¢„æµ‹ç»“æœï¼ˆæŒ‰æµ‹ç‚¹åˆ†ç¦»å­˜å‚¨ï¼‰

```python
def prediction_inference_thread(ctx: AppContext):
    logger = ctx.loggers["prediction_inference"]

    # å‡è®¾å·²å®Œæˆé¢„æµ‹æ¨ç†ï¼Œå¾—åˆ°é¢„æµ‹ç»“æœ
    prediction_results = {
        'sensor_temp_A1': 25.5,
        'sensor_temp_B2': 26.1,
        'sensor_temp_C3': 24.8
    }

    # å†™å…¥é¢„æµ‹ç»“æœ
    success = ctx.data_writer.write_influxdb_data(
        'prediction_data_client',    # ä½¿ç”¨é¢„æµ‹æ•°æ®å®¢æˆ·ç«¯
        'prediction_by_uid',         # æŒ‰æµ‹ç‚¹åˆ†ç¦»å­˜å‚¨
        prediction_results,           # ä¸»è¦æ•°æ®
        horizon='15mins'              # é™„åŠ å‚æ•°ï¼šé¢„æµ‹æ—¶é—´èŒƒå›´
    )

    if success:
        logger.info("é¢„æµ‹ç»“æœå†™å…¥æˆåŠŸ")
    else:
        logger.error("é¢„æµ‹ç»“æœå†™å…¥å¤±è´¥")
```

#### ç¤ºä¾‹ 2: å†™å…¥é¢„æµ‹ç»“æœï¼ˆç»Ÿä¸€æ ¼å¼å­˜å‚¨ï¼ŒåŒ…å«ç½®ä¿¡åº¦ï¼‰

```python
import json

# æ„å»ºå¸¦ç½®ä¿¡åº¦çš„é¢„æµ‹æ•°æ®
prediction_data = {
    'sensor_temp_A1': json.dumps({
        "value": 25.5,
        "confidence": 0.95,
        "model_version": "v1.2"
    }),
    'sensor_temp_B2': json.dumps({
        "value": 26.1,
        "confidence": 0.93,
        "model_version": "v1.2"
    })
}

success = ctx.data_writer.write_influxdb_data(
    'prediction_data_client',
    'prediction_unified',      # ç»Ÿä¸€æ ¼å¼å­˜å‚¨
    prediction_data,
    horizon='1h'               # 1å°æ—¶é¢„æµ‹
)
```

#### ç¤ºä¾‹ 3: å†™å…¥ä¼˜åŒ–æ§åˆ¶æŒ‡ä»¤

```python
def optimization_thread(ctx: AppContext):
    logger = ctx.loggers["optimization"]

    # ä¼˜åŒ–ç®—æ³•å¾—åˆ°çš„æ§åˆ¶æŒ‡ä»¤
    control_commands = {
        'ac_a1_001_supply_temp_setpoint': 24.0,
        'ac_a1_002_supply_temp_setpoint': 24.5,
        'ch_001_chilled_water_temp_setpoint': 7.0
    }

    # å†™å…¥æ§åˆ¶æŒ‡ä»¤ï¼ˆæŒ‰æµ‹ç‚¹åˆ†ç¦»å­˜å‚¨ï¼‰
    success = ctx.data_writer.write_influxdb_data(
        'optimization_data_client',
        'optimization_by_uid',
        control_commands,
        is_auto_execute=False     # æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œ
    )

    if success:
        logger.info("æ§åˆ¶æŒ‡ä»¤å†™å…¥æˆåŠŸ")
```

---

## 5. å…³é”®æ“ä½œä¿æŠ¤æ¥å£

### 5.1 ä»€ä¹ˆæ˜¯å…³é”®æ“ä½œï¼Ÿ

**å…³é”®æ“ä½œ**æŒ‡é‚£äº›**ä¸èƒ½è¢«ä¸­æ–­**çš„æ“ä½œï¼Œä¾‹å¦‚ï¼š
- æ¨¡å‹ä¿å­˜ï¼ˆå†™å…¥ checkpointï¼‰
- æ•°æ®åº“æ‰¹é‡å†™å…¥
- é…ç½®æ–‡ä»¶ä¿å­˜

å¦‚æœè¿™äº›æ“ä½œè¢«ä¸­é€”ä¸­æ–­ï¼Œå¯èƒ½å¯¼è‡´ï¼š
- æ¨¡å‹æ–‡ä»¶æŸå
- æ•°æ®ä¸å®Œæ•´
- ç³»ç»ŸçŠ¶æ€ä¸ä¸€è‡´

### 5.2 æ¥å£å®šä¹‰

```python
from utils.critical_operation import critical_operation

@contextmanager
def critical_operation(ctx: 'AppContext'):
    """
    åŠŸèƒ½: ä¿æŠ¤å…³é”®æ“ä½œï¼Œç¡®ä¿ä¸ä¼šè¢«ç¨‹åºé€€å‡ºä¿¡å·ä¸­æ–­

    åŸç†:
        - è¿›å…¥æ—¶ï¼šå¢åŠ å…³é”®æ“ä½œè®¡æ•°å™¨
        - é€€å‡ºæ—¶ï¼šå‡å°‘å…³é”®æ“ä½œè®¡æ•°å™¨
        - ä¸»çº¿ç¨‹é€€å‡ºæ—¶ä¼šç­‰å¾…æ‰€æœ‰å…³é”®æ“ä½œå®Œæˆ

    ä½¿ç”¨åœºæ™¯:
        - ä¿å­˜æ¨¡å‹æ–‡ä»¶
        - æ‰¹é‡å†™å…¥æ•°æ®åº“
        - ä¿å­˜é…ç½®/çŠ¶æ€æ–‡ä»¶

    æ³¨æ„:
        - ä»…åœ¨çœŸæ­£å…³é”®çš„æ“ä½œå¤„ä½¿ç”¨
        - å…³é”®æ“ä½œåº”å°½å¯èƒ½å¿«é€Ÿå®Œæˆï¼ˆå»ºè®® < 5ç§’ï¼‰
        - ä¸è¦åœ¨é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ä¸­ä½¿ç”¨ï¼ˆå¦‚è®­ç»ƒå¾ªç¯ï¼‰
    """
```

### 5.3 ä½¿ç”¨ç¤ºä¾‹

#### ç¤ºä¾‹ 1: ä¿æŠ¤æ¨¡å‹ä¿å­˜æ“ä½œ

```python
from utils.critical_operation import critical_operation

def prediction_training_thread(ctx: AppContext):
    logger = ctx.loggers["prediction_training"]

    # è®­ç»ƒæ¨¡å‹...
    model = train_model(data)

    # âš ï¸ ä½¿ç”¨ critical_operation ä¿æŠ¤æ¨¡å‹ä¿å­˜
    with critical_operation(ctx):
        logger.info("å¼€å§‹ä¿å­˜æ¨¡å‹...")
        model.save("pth/prediction_model.pth")
        logger.info("æ¨¡å‹ä¿å­˜å®Œæˆ")
```

#### ç¤ºä¾‹ 2: ä¿æŠ¤æ‰¹é‡æ•°æ®å†™å…¥

```python
from utils.critical_operation import critical_operation

def save_training_history(ctx: AppContext, history_data: dict):
    """ä¿å­˜è®­ç»ƒå†å²åˆ°æ–‡ä»¶"""
    logger = ctx.loggers["prediction_training"]

    with critical_operation(ctx):
        with open("logs/training_history.json", "w") as f:
            json.dump(history_data, f)
        logger.info("è®­ç»ƒå†å²ä¿å­˜å®Œæˆ")
```

### 5.4 å·¥ä½œåŸç†å›¾

```
ç”¨æˆ·æŒ‰ Ctrl+C é€€å‡º
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  shutdown_event.set()                â”‚
â”‚  (é€šçŸ¥æ‰€æœ‰å·¥ä½œçº¿ç¨‹é€€å‡º)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  wait_for_critical_operations()     â”‚
â”‚  ç­‰å¾…å…³é”®æ“ä½œè®¡æ•°å™¨å˜ä¸º 0             â”‚
â”‚  (æœ€å¤šç­‰å¾… shutdown.timeout ç§’)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å…³é—­ InfluxDB è¿æ¥                  â”‚
â”‚  åˆ·æ–°æ—¥å¿—                            â”‚
â”‚  ç¨‹åºé€€å‡º                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.5 é‡è¦æé†’

```python
# âŒ é”™è¯¯ç”¨æ³•ï¼šåœ¨é•¿æ—¶é—´æ“ä½œä¸­ä½¿ç”¨ critical_operation
with critical_operation(ctx):
    for epoch in range(1000):
        train_one_epoch(model, data)  # æ¯ä¸ª epoch å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ
        # è¿™ä¼šé˜»æ­¢ç¨‹åºæ­£å¸¸é€€å‡ºï¼

# âœ… æ­£ç¡®ç”¨æ³•ï¼šåªä¿æŠ¤å¿…è¦çš„ä¿å­˜æ“ä½œ
for epoch in range(1000):
    if ctx.shutdown_event.is_set():
        break  # æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œé€€å‡ºè®­ç»ƒå¾ªç¯

    train_one_epoch(model, data)

    # ä»…åœ¨ä¿å­˜æ—¶ä½¿ç”¨ critical_operation
    if epoch % 100 == 0:
        with critical_operation(ctx):
            model.save(f"checkpoint_{epoch}.pth")
```

---

## 6. çº¿ç¨‹æ§åˆ¶æ¥å£

### 6.1 shutdown_event æ¦‚è¿°

`ctx.shutdown_event` æ˜¯ä¸€ä¸ª `threading.Event` å¯¹è±¡ï¼Œç”¨äºé€šçŸ¥æ‰€æœ‰å·¥ä½œçº¿ç¨‹ä¼˜é›…é€€å‡ºã€‚

### 6.2 æ ¸å¿ƒæ–¹æ³•

#### 6.2.1 æ£€æŸ¥æ˜¯å¦æ”¶åˆ°å…³é—­ä¿¡å·

```python
def is_set() -> bool:
    """
    åŠŸèƒ½: æ£€æŸ¥æ˜¯å¦æ”¶åˆ°å…³é—­ä¿¡å·

    è¿”å›:
        bool: True è¡¨ç¤ºæ”¶åˆ°å…³é—­ä¿¡å·ï¼Œåº”è¯¥é€€å‡º
              False è¡¨ç¤ºç»§ç»­æ­£å¸¸è¿è¡Œ

    ä½¿ç”¨åœºæ™¯:
        - åœ¨é•¿æ—¶é—´è¿è¡Œçš„å¾ªç¯ä¸­å®šæœŸæ£€æŸ¥
        - åœ¨æ¯ä¸ªå¾ªç¯è¿­ä»£å¼€å§‹æ—¶æ£€æŸ¥
    """
```

#### 6.2.2 ç­‰å¾…å…³é—­ä¿¡å·ï¼ˆå¸¦è¶…æ—¶ï¼‰

```python
def wait(timeout: float = None) -> bool:
    """
    åŠŸèƒ½: ç­‰å¾…å…³é—­ä¿¡å·

    å‚æ•°:
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™ç­‰å¾…

    è¿”å›:
        bool: True è¡¨ç¤ºæ”¶åˆ°å…³é—­ä¿¡å·
              False è¡¨ç¤ºè¶…æ—¶ï¼ˆæœªæ”¶åˆ°ä¿¡å·ï¼‰

    ä½¿ç”¨åœºæ™¯:
        - çº¿ç¨‹é—´éš”ç­‰å¾…æ—¶ï¼Œæ›¿ä»£ time.sleep()
        - å¯ä»¥åœ¨ç­‰å¾…æœŸé—´å“åº”é€€å‡ºä¿¡å·
    """
```

### 6.3 ä½¿ç”¨ç¤ºä¾‹

#### ç¤ºä¾‹ 1: ä¸»å¾ªç¯ä¸­æ£€æŸ¥å…³é—­ä¿¡å·

```python
def prediction_training_thread(ctx: AppContext):
    logger = ctx.loggers["prediction_training"]

    # ä¸»å¾ªç¯ï¼šå½“æ”¶åˆ°å…³é—­ä¿¡å·æ—¶é€€å‡º
    while not ctx.shutdown_event.is_set():
        try:
            # æ‰§è¡Œä¸€æ¬¡è®­ç»ƒå‘¨æœŸ
            perform_training_cycle(ctx)

            # ä½¿ç”¨ wait() æ›¿ä»£ time.sleep()
            # å¥½å¤„ï¼šå¯ä»¥ç«‹å³å“åº”é€€å‡ºä¿¡å·
            if ctx.shutdown_event.wait(timeout=3600):
                break  # æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œé€€å‡ºå¾ªç¯

        except Exception as e:
            logger.error(f"è®­ç»ƒå‡ºé”™: {e}")
            if ctx.shutdown_event.wait(timeout=60):
                break

    logger.info("çº¿ç¨‹å·²é€€å‡º")
```

#### ç¤ºä¾‹ 2: åœ¨é•¿æ—¶é—´ä»»åŠ¡ä¸­å®šæœŸæ£€æŸ¥

```python
def train_model(ctx: AppContext, model, dataloader):
    """è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒä¸­é€”é€€å‡º"""
    logger = ctx.loggers["prediction_training"]

    for epoch in range(num_epochs):
        # âš ï¸ æ¯ä¸ª epoch å¼€å§‹æ—¶æ£€æŸ¥é€€å‡ºä¿¡å·
        if ctx.shutdown_event.is_set():
            logger.info(f"æ£€æµ‹åˆ°å…³é—­ä¿¡å·ï¼Œåœ¨ç¬¬ {epoch} ä¸ª epoch åä¸­æ–­è®­ç»ƒ")
            break

        for batch_idx, (data, target) in enumerate(dataloader):
            # å¯¹äºå¤§æ•°æ®é›†ï¼Œä¹Ÿåœ¨ batch çº§åˆ«æ£€æŸ¥
            if batch_idx % 100 == 0 and ctx.shutdown_event.is_set():
                logger.info("æ£€æµ‹åˆ°å…³é—­ä¿¡å·ï¼Œä¸­æ–­å½“å‰ epoch")
                return

            # æ‰§è¡Œè®­ç»ƒæ­¥éª¤
            train_step(model, data, target)

    logger.info("è®­ç»ƒå®Œæˆ")
```

#### ç¤ºä¾‹ 3: ä¼˜åŒ–å¾ªç¯ä¸­çš„æ£€æŸ¥

```python
def run_optimization(ctx: AppContext, max_iterations=1000):
    """è¿è¡Œä¼˜åŒ–ç®—æ³•ï¼Œæ”¯æŒä¸­é€”é€€å‡º"""
    logger = ctx.loggers["optimization"]

    for step in range(max_iterations):
        # å®šæœŸæ£€æŸ¥é€€å‡ºä¿¡å·
        if ctx.shutdown_event.is_set():
            logger.info(f"åœ¨ç¬¬ {step} æ­¥ä¸­æ–­ä¼˜åŒ–")
            break

        # æ‰§è¡Œä¼˜åŒ–æ­¥éª¤
        result = optimization_step(step)

        # æ¯ 100 æ­¥è®°å½•ä¸€æ¬¡è¿›åº¦
        if step % 100 == 0:
            logger.info(f"ä¼˜åŒ–è¿›åº¦: {step}/{max_iterations}")

    return result
```

### 6.4 æœ€ä½³å®è·µæ€»ç»“

| åœºæ™¯ | æ¨èåšæ³• |
|------|---------|
| ä¸»å¾ªç¯æ¡ä»¶ | `while not ctx.shutdown_event.is_set():` |
| é—´éš”ç­‰å¾… | ç”¨ `ctx.shutdown_event.wait(timeout=N)` æ›¿ä»£ `time.sleep(N)` |
| é•¿æ—¶é—´ä»»åŠ¡ | åœ¨å¾ªç¯ä¸­å®šæœŸè°ƒç”¨ `if ctx.shutdown_event.is_set(): break` |
| åµŒå¥—å¾ªç¯ | å¤–å±‚å¾ªç¯æ£€æŸ¥ä¸€æ¬¡ï¼Œå†…å±‚æ ¹æ®æƒ…å†µå®šæœŸæ£€æŸ¥ |

---

## 7. æ¨¡å—å¼€å‘æŒ‡å—

### 7.1 å¾…å¼€å‘æ¨¡å—æ¦‚è¿°

ç›®å‰ä»¥ä¸‹ä¸¤ä¸ªæ¨¡å—ä¸ºç©ºï¼Œéœ€è¦å¼€å‘è€…å®ç°ï¼š

| æ¨¡å—æ–‡ä»¶ | ä½ç½® | ç”¨é€” |
|---------|------|------|
| `prediction_module.py` | `modules/` | é¢„æµ‹æ¨¡å‹ç›¸å…³åŠŸèƒ½ |
| `optimization_module.py` | `modules/` | ä¼˜åŒ–ç®—æ³•ç›¸å…³åŠŸèƒ½ |

### 7.2 prediction_module.py å¼€å‘æ¨¡æ¿

```python
"""
é¢„æµ‹æ¨¡å— - å®ç°é¢„æµ‹æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†åŠŸèƒ½

æœ¬æ¨¡å—æä¾›:
1. æ•°æ®é¢„å¤„ç†å‡½æ•°
2. æ¨¡å‹è®­ç»ƒå‡½æ•°
3. æ¨¡å‹æ¨ç†å‡½æ•°
4. æ¨¡å‹åŠ è½½/ä¿å­˜å‡½æ•°
"""

import torch
import pandas as pd
from typing import Dict, Any, Tuple, Optional
from pathlib import Path

# ç±»å‹æç¤ºï¼šé¿å…å¾ªç¯å¯¼å…¥
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from DC_Energy_conservation.main import AppContext


# ==================== æ•°æ®é¢„å¤„ç† ====================

def preprocess_training_data(
    observable_data: Dict[str, pd.DataFrame],
    ctx: 'AppContext'
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    é¢„å¤„ç†è®­ç»ƒæ•°æ®

    å‚æ•°:
        observable_data: ä» InfluxDB è¯»å–çš„åŸå§‹æ•°æ®
        ctx: åº”ç”¨ä¸Šä¸‹æ–‡ï¼ˆç”¨äºè®¿é—®é…ç½®ï¼‰

    è¿”å›:
        Tuple[features, labels]: è®­ç»ƒç‰¹å¾å’Œæ ‡ç­¾
    """
    logger = ctx.loggers["prediction_training"]

    # è·å–é¢„å¤„ç†é…ç½®
    preprocess_config = ctx.modules_config.get("prediction", {}).get("preprocessing", {})

    # TODO: å®ç°æ•°æ®é¢„å¤„ç†é€»è¾‘
    # 1. æ•°æ®æ¸…æ´—ï¼ˆå¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ï¼‰
    # 2. ç‰¹å¾å·¥ç¨‹ï¼ˆæ—¶é—´ç‰¹å¾ã€æ»åç‰¹å¾ç­‰ï¼‰
    # 3. æ•°æ®å½’ä¸€åŒ–
    # 4. æ„å»ºè®­ç»ƒæ ·æœ¬

    logger.info("æ•°æ®é¢„å¤„ç†å®Œæˆ")

    # ç¤ºä¾‹è¿”å›ï¼ˆéœ€æ›¿æ¢ä¸ºå®é™…å®ç°ï¼‰
    features = torch.zeros((100, 10))  # 100ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç‰¹å¾
    labels = torch.zeros((100, 1))     # 100ä¸ªæ ‡ç­¾

    return features, labels


def preprocess_inference_data(
    observable_data: Dict[str, pd.DataFrame],
    ctx: 'AppContext'
) -> torch.Tensor:
    """
    é¢„å¤„ç†æ¨ç†æ•°æ®

    å‚æ•°:
        observable_data: ä» InfluxDB è¯»å–çš„æœ€æ–°æ•°æ®
        ctx: åº”ç”¨ä¸Šä¸‹æ–‡

    è¿”å›:
        torch.Tensor: æ¨ç†è¾“å…¥ç‰¹å¾
    """
    # TODO: å®ç°æ¨ç†æ•°æ®é¢„å¤„ç†
    pass


# ==================== æ¨¡å‹å®šä¹‰ ====================

class PredictionModel(torch.nn.Module):
    """é¢„æµ‹æ¨¡å‹å®šä¹‰"""

    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):
        super().__init__()
        self.network = torch.nn.Sequential(
            torch.nn.Linear(input_dim, hidden_dim),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_dim, hidden_dim),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_dim, output_dim)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)


# ==================== æ¨¡å‹è®­ç»ƒ ====================

def train_prediction_model(
    features: torch.Tensor,
    labels: torch.Tensor,
    ctx: 'AppContext',
    epochs: int = 100
) -> PredictionModel:
    """
    è®­ç»ƒé¢„æµ‹æ¨¡å‹

    å‚æ•°:
        features: è®­ç»ƒç‰¹å¾
        labels: è®­ç»ƒæ ‡ç­¾
        ctx: åº”ç”¨ä¸Šä¸‹æ–‡
        epochs: è®­ç»ƒè½®æ•°

    è¿”å›:
        PredictionModel: è®­ç»ƒå¥½çš„æ¨¡å‹
    """
    logger = ctx.loggers["prediction_training"]

    # ä»é…ç½®è·å–æ¨¡å‹å‚æ•°
    model_config = ctx.models_config.get("prediction_model", {})
    hidden_dim = model_config.get("hidden_dim", 64)
    learning_rate = model_config.get("learning_rate", 0.001)

    # åˆå§‹åŒ–æ¨¡å‹
    model = PredictionModel(
        input_dim=features.shape[1],
        hidden_dim=hidden_dim,
        output_dim=labels.shape[1]
    )

    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    criterion = torch.nn.MSELoss()

    # è®­ç»ƒå¾ªç¯
    for epoch in range(epochs):
        # âš ï¸ é‡è¦ï¼šå®šæœŸæ£€æŸ¥å…³é—­ä¿¡å·
        if ctx.shutdown_event.is_set():
            logger.info(f"æ£€æµ‹åˆ°å…³é—­ä¿¡å·ï¼Œåœ¨ç¬¬ {epoch} ä¸ª epoch åä¸­æ–­è®­ç»ƒ")
            break

        optimizer.zero_grad()
        outputs = model(features)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        if epoch % 10 == 0:
            logger.info(f"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}")

    return model


# ==================== æ¨¡å‹æ¨ç† ====================

def predict(
    model: PredictionModel,
    input_features: torch.Tensor,
    ctx: 'AppContext'
) -> Dict[str, float]:
    """
    æ‰§è¡Œé¢„æµ‹æ¨ç†

    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        input_features: è¾“å…¥ç‰¹å¾
        ctx: åº”ç”¨ä¸Šä¸‹æ–‡

    è¿”å›:
        Dict[str, float]: uid -> é¢„æµ‹å€¼ çš„æ˜ å°„
    """
    logger = ctx.loggers["prediction_inference"]

    model.eval()
    with torch.no_grad():
        predictions = model(input_features)

    # TODO: å°†é¢„æµ‹ç»“æœæ˜ å°„å› uid
    results = {
        "sensor_temp_A1": float(predictions[0, 0]),
        # ...
    }

    logger.info(f"é¢„æµ‹å®Œæˆï¼Œå…± {len(results)} ä¸ªé¢„æµ‹å€¼")
    return results


# ==================== æ¨¡å‹åŠ è½½/ä¿å­˜ ====================

def save_model(
    model: PredictionModel,
    save_path: str,
    ctx: 'AppContext'
) -> None:
    """
    ä¿å­˜æ¨¡å‹ï¼ˆä½¿ç”¨ critical_operation ä¿æŠ¤ï¼‰
    """
    from utils.critical_operation import critical_operation

    logger = ctx.loggers["prediction_training"]

    with critical_operation(ctx):
        torch.save(model.state_dict(), save_path)
        logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")


def load_model(
    model_path: str,
    ctx: 'AppContext'
) -> Optional[PredictionModel]:
    """
    åŠ è½½æ¨¡å‹
    """
    logger = ctx.loggers["prediction_inference"]

    if not Path(model_path).exists():
        logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None

    # ä»é…ç½®è·å–æ¨¡å‹å‚æ•°
    model_config = ctx.models_config.get("prediction_model", {})

    model = PredictionModel(
        input_dim=model_config.get("input_dim", 10),
        hidden_dim=model_config.get("hidden_dim", 64),
        output_dim=model_config.get("output_dim", 1)
    )
    model.load_state_dict(torch.load(model_path))
    model.eval()

    logger.info(f"æ¨¡å‹å·²åŠ è½½: {model_path}")
    return model
```

### 7.3 optimization_module.py å¼€å‘æ¨¡æ¿

```python
"""
ä¼˜åŒ–æ¨¡å— - å®ç°ä¼˜åŒ–ç®—æ³•

æœ¬æ¨¡å—æä¾›:
1. ä¼˜åŒ–é—®é¢˜å®šä¹‰
2. çº¦æŸå¤„ç†
3. ä¼˜åŒ–æ±‚è§£
4. æ§åˆ¶æŒ‡ä»¤ç”Ÿæˆ
"""

import numpy as np
from typing import Dict, Any, List, Optional
from scipy.optimize import minimize

from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from DC_Energy_conservation.main import AppContext


# ==================== ä¼˜åŒ–é—®é¢˜å®šä¹‰ ====================

class EnergyOptimizationProblem:
    """æ•°æ®ä¸­å¿ƒèƒ½è€—ä¼˜åŒ–é—®é¢˜"""

    def __init__(self, ctx: 'AppContext'):
        self.ctx = ctx
        self.logger = ctx.loggers["optimization"]

        # ä»é…ç½®åŠ è½½å®‰å…¨è¾¹ç•Œ
        self.boundaries = ctx.security_boundary_config

    def objective_function(self, x: np.ndarray, predictions: Dict) -> float:
        """
        ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–èƒ½è€—

        å‚æ•°:
            x: å†³ç­–å˜é‡ï¼ˆæ§åˆ¶è®¾å®šç‚¹ï¼‰
            predictions: é¢„æµ‹ç»“æœ

        è¿”å›:
            float: ç›®æ ‡å‡½æ•°å€¼ï¼ˆèƒ½è€—ä¼°è®¡ï¼‰
        """
        # TODO: å®ç°ç›®æ ‡å‡½æ•°
        # é€šå¸¸æ˜¯åŸºäºé¢„æµ‹æ¨¡å‹è®¡ç®—èƒ½è€—
        energy_consumption = np.sum(x ** 2)  # ç¤ºä¾‹
        return energy_consumption

    def constraint_temperature(self, x: np.ndarray, predictions: Dict) -> float:
        """
        çº¦æŸå‡½æ•°ï¼šæ¸©åº¦çº¦æŸ

        è¿”å›:
            float: >= 0 è¡¨ç¤ºæ»¡è¶³çº¦æŸ
        """
        # ä»å®‰å…¨è¾¹ç•Œé…ç½®è·å–æ¸©åº¦é™åˆ¶
        max_temp = self.boundaries.get("temperature", {}).get("max", 27.0)

        # TODO: åŸºäºé¢„æµ‹è®¡ç®—é¢„æœŸæ¸©åº¦
        expected_temp = 25.0  # ç¤ºä¾‹

        return max_temp - expected_temp


# ==================== ä¼˜åŒ–æ±‚è§£ ====================

def solve_optimization(
    ctx: 'AppContext',
    current_status: Dict[str, Any],
    predictions: Dict[str, float]
) -> Dict[str, float]:
    """
    æ±‚è§£ä¼˜åŒ–é—®é¢˜

    å‚æ•°:
        ctx: åº”ç”¨ä¸Šä¸‹æ–‡
        current_status: å½“å‰çŠ¶æ€æ•°æ®
        predictions: é¢„æµ‹ç»“æœ

    è¿”å›:
        Dict[str, float]: ä¼˜åŒ–åçš„æ§åˆ¶è®¾å®šç‚¹
    """
    logger = ctx.loggers["optimization"]

    # åˆ›å»ºä¼˜åŒ–é—®é¢˜
    problem = EnergyOptimizationProblem(ctx)

    # åˆå§‹åŒ–å†³ç­–å˜é‡ï¼ˆä½¿ç”¨å½“å‰è®¾å®šç‚¹ï¼‰
    x0 = np.array([24.0, 24.5, 7.0])  # ç¤ºä¾‹ï¼š[AC1æ¸©åº¦, AC2æ¸©åº¦, å†·å†»æ°´æ¸©åº¦]

    # å®šä¹‰å˜é‡è¾¹ç•Œ
    bounds = [
        (22.0, 28.0),  # AC1 é€é£æ¸©åº¦èŒƒå›´
        (22.0, 28.0),  # AC2 é€é£æ¸©åº¦èŒƒå›´
        (5.0, 12.0),   # å†·å†»æ°´å‡ºæ°´æ¸©åº¦èŒƒå›´
    ]

    # å®šä¹‰çº¦æŸ
    constraints = [
        {'type': 'ineq', 'fun': lambda x: problem.constraint_temperature(x, predictions)}
    ]

    # æ±‚è§£ä¼˜åŒ–é—®é¢˜
    logger.info("å¼€å§‹æ±‚è§£ä¼˜åŒ–é—®é¢˜...")

    result = minimize(
        fun=problem.objective_function,
        x0=x0,
        args=(predictions,),
        method='SLSQP',
        bounds=bounds,
        constraints=constraints,
        options={'maxiter': 100}
    )

    if result.success:
        logger.info(f"ä¼˜åŒ–æˆåŠŸï¼Œç›®æ ‡å‡½æ•°å€¼: {result.fun:.4f}")
    else:
        logger.warning(f"ä¼˜åŒ–æœªæ”¶æ•›: {result.message}")

    # æ„å»ºæ§åˆ¶æŒ‡ä»¤
    control_commands = {
        'ac_a1_001_supply_temp_setpoint': float(result.x[0]),
        'ac_a1_002_supply_temp_setpoint': float(result.x[1]),
        'ch_001_chilled_water_temp_setpoint': float(result.x[2]),
    }

    return control_commands


# ==================== å®‰å…¨æ£€æŸ¥ ====================

def validate_control_commands(
    commands: Dict[str, float],
    ctx: 'AppContext'
) -> Dict[str, float]:
    """
    éªŒè¯å¹¶é™åˆ¶æ§åˆ¶æŒ‡ä»¤åœ¨å®‰å…¨èŒƒå›´å†…

    å‚æ•°:
        commands: åŸå§‹æ§åˆ¶æŒ‡ä»¤
        ctx: åº”ç”¨ä¸Šä¸‹æ–‡

    è¿”å›:
        Dict[str, float]: éªŒè¯åçš„å®‰å…¨æ§åˆ¶æŒ‡ä»¤
    """
    logger = ctx.loggers["optimization"]
    boundaries = ctx.security_boundary_config

    safe_commands = {}

    for uid, value in commands.items():
        # è·å–è¯¥æ§åˆ¶ç‚¹çš„å®‰å…¨èŒƒå›´
        if uid in boundaries.get("control_points", {}):
            limits = boundaries["control_points"][uid]
            min_val = limits.get("min", float('-inf'))
            max_val = limits.get("max", float('inf'))

            # é™åˆ¶åœ¨å®‰å…¨èŒƒå›´å†…
            safe_value = max(min_val, min(max_val, value))

            if safe_value != value:
                logger.warning(f"{uid}: å€¼ {value} è¢«é™åˆ¶åˆ°å®‰å…¨èŒƒå›´ [{min_val}, {max_val}] -> {safe_value}")

            safe_commands[uid] = safe_value
        else:
            safe_commands[uid] = value

    return safe_commands
```

---

## 8. å¼€å‘æ³¨æ„äº‹é¡¹

### 8.1 çº¿ç¨‹å®‰å…¨æ³¨æ„äº‹é¡¹

#### 8.1.1 å®‰å…¨çš„å…±äº«èµ„æº

ä»¥ä¸‹èµ„æºæ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå¯ä»¥åœ¨å¤šä¸ªçº¿ç¨‹ä¸­ç›´æ¥ä½¿ç”¨ï¼š

| èµ„æº | è¯´æ˜ |
|------|------|
| `ctx.loggers` | Python logging æ¨¡å—æœ¬èº«æ˜¯çº¿ç¨‹å®‰å…¨çš„ |
| `ctx.*_config` | æ‰€æœ‰é…ç½®æ–‡ä»¶åœ¨å¯åŠ¨æ—¶åŠ è½½ï¼Œè¿è¡ŒæœŸé—´åªè¯» |
| `ctx.shutdown_event` | `threading.Event` æ˜¯çº¿ç¨‹å®‰å…¨çš„ |
| `ctx.data_reader` | å†…éƒ¨ä½¿ç”¨äº†çº¿ç¨‹å®‰å…¨çš„æœºåˆ¶ |
| `ctx.data_writer` | å†…éƒ¨ä½¿ç”¨äº† `critical_operation` ä¿æŠ¤ |

#### 8.1.2 éœ€è¦æ³¨æ„çš„æ“ä½œ

```python
# âŒ ä¸è¦åœ¨è¿è¡Œæ—¶ä¿®æ”¹é…ç½®
ctx.main_config["threads"]["interval"] = 100  # ä¸å®‰å…¨ï¼

# âœ… é…ç½®åº”è¯¥åªè¯»
interval = ctx.main_config["threads"]["prediction_training"]["interval"]

# âŒ ä¸è¦åœ¨å¤šä¸ªçº¿ç¨‹é—´å…±äº«å¯å˜çŠ¶æ€ï¼ˆä¸ä½¿ç”¨é”ä¿æŠ¤ï¼‰
shared_model = None  # å…¨å±€å˜é‡ï¼Œå¯èƒ½å¯¼è‡´ç«æ€æ¡ä»¶

# âœ… ä½¿ç”¨å±€éƒ¨å˜é‡æˆ–çº¿ç¨‹å®‰å…¨æœºåˆ¶
def prediction_inference_thread(ctx):
    model = load_model("model.pth")  # æ¯ä¸ªçº¿ç¨‹åŠ è½½è‡ªå·±çš„æ¨¡å‹å®ä¾‹
```

### 8.2 é”™è¯¯å¤„ç†è§„èŒƒ

#### 8.2.1 æ ‡å‡†é”™è¯¯å¤„ç†æ¨¡å¼

```python
def your_thread_function(ctx: AppContext):
    logger = ctx.loggers["your_logger"]
    error_retry_wait = 60  # é”™è¯¯é‡è¯•ç­‰å¾…æ—¶é—´

    while not ctx.shutdown_event.is_set():
        try:
            # ä¸»è¦é€»è¾‘
            perform_task(ctx)

        except ValueError as e:
            # ä¸šåŠ¡é€»è¾‘é”™è¯¯ï¼šè®°å½•å¹¶ç»§ç»­
            logger.warning(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
            continue

        except ConnectionError as e:
            # è¿æ¥é”™è¯¯ï¼šç­‰å¾…åé‡è¯•
            logger.error(f"è¿æ¥å¤±è´¥: {e}ï¼Œ{error_retry_wait}ç§’åé‡è¯•")
            if ctx.shutdown_event.wait(timeout=error_retry_wait):
                break
            continue

        except Exception as e:
            # æœªçŸ¥é”™è¯¯ï¼šè®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œç­‰å¾…åé‡è¯•
            logger.error(f"æœªçŸ¥é”™è¯¯: {e}", exc_info=True)
            if ctx.shutdown_event.wait(timeout=error_retry_wait):
                break
```

#### 8.2.2 æ•°æ®éªŒè¯æ¨¡å¼

```python
from DC_Energy_conservation.main import validate_data_and_wait_on_error_retry

# ä½¿ç”¨å†…ç½®çš„æ•°æ®éªŒè¯å‡½æ•°
observable_data = ctx.data_reader.read_influxdb_data(...)

should_continue, should_break = validate_data_and_wait_on_error_retry(
    data=observable_data,
    data_type="çŠ¶æ€æ•°æ®",
    error_retry_wait=60,
    shutdown_event=ctx.shutdown_event,
    logger=logger
)

if should_break:
    break  # æ”¶åˆ°å…³é—­ä¿¡å·
if should_continue:
    continue  # æ•°æ®æ— æ•ˆï¼Œè·³è¿‡æœ¬æ¬¡
```

### 8.3 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 8.3.1 æ•°æ®è¯»å–ä¼˜åŒ–

```python
# âŒ é¢‘ç¹è¯»å–å…¨é‡æ•°æ®
for i in range(1000):
    data = ctx.data_reader.read_influxdb_data(...)  # æ¯æ¬¡éƒ½æŸ¥è¯¢æ•°æ®åº“

# âœ… æ‰¹é‡è¯»å–ï¼Œæœ¬åœ°å¤„ç†
data = ctx.data_reader.read_influxdb_data(...)  # ä¸€æ¬¡è¯»å–
for i in range(1000):
    process(data)  # æœ¬åœ°å¤„ç†
```

#### 8.3.2 æ¨¡å‹æ¨ç†ä¼˜åŒ–

```python
# âŒ æ¯æ¬¡æ¨ç†éƒ½åŠ è½½æ¨¡å‹
def inference(ctx):
    model = load_model("model.pth")  # æ¯æ¬¡éƒ½ä»ç£ç›˜åŠ è½½
    result = model(input_data)

# âœ… ç¼“å­˜æ¨¡å‹ï¼Œåªåœ¨éœ€è¦æ—¶é‡æ–°åŠ è½½
class InferenceEngine:
    def __init__(self, ctx):
        self.ctx = ctx
        self.model = None
        self.model_version = None

    def load_if_updated(self, model_path: str):
        current_version = get_model_version(model_path)
        if current_version != self.model_version:
            self.model = load_model(model_path)
            self.model_version = current_version
```

#### 8.3.3 æ‰¹é‡å†™å…¥ä¼˜åŒ–

```python
# âŒ é€æ¡å†™å…¥
for uid, value in predictions.items():
    ctx.data_writer.write_influxdb_data(..., {uid: value})

# âœ… æ‰¹é‡å†™å…¥ï¼ˆdata_writer å†…éƒ¨å·²å®ç°æ‰¹é‡å¤„ç†ï¼‰
ctx.data_writer.write_influxdb_data(..., predictions)  # ä¸€æ¬¡å†™å…¥æ‰€æœ‰æ•°æ®
```

### 8.4 æ—¥å¿—è§„èŒƒ

#### 8.4.1 æ—¥å¿—å™¨é€‰æ‹©

| çº¿ç¨‹/æ¨¡å— | æ—¥å¿—å™¨åç§° | æ—¥å¿—æ–‡ä»¶ |
|----------|-----------|---------|
| é¢„æµ‹è®­ç»ƒ | `ctx.loggers["prediction_training"]` | `prediction_training_log.log` |
| é¢„æµ‹æ¨ç† | `ctx.loggers["prediction_inference"]` | `prediction_inference_log.log` |
| ä¼˜åŒ– | `ctx.loggers["optimization"]` | `optimization_log.log` |
| InfluxDBæ“ä½œ | `ctx.loggers["influxdb"]` | `influxdb_log.log` |
| ä¸»ç¨‹åº | `ctx.loggers["main"]` | `main_log.log` |

#### 8.4.2 æ—¥å¿—çº§åˆ«ä½¿ç”¨

```python
logger = ctx.loggers["prediction_training"]

# DEBUG: è°ƒè¯•ä¿¡æ¯ï¼ˆç”Ÿäº§ç¯å¢ƒé€šå¸¸å…³é—­ï¼‰
logger.debug(f"å¤„ç†æ•°æ®ç‚¹: {uid}, å€¼: {value}")

# INFO: æ­£å¸¸è¿è¡Œä¿¡æ¯
logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
logger.info(f"æˆåŠŸè¯»å– {len(data)} æ¡æ•°æ®")

# WARNING: è­¦å‘Šä¿¡æ¯ï¼ˆå¯æ¢å¤çš„é—®é¢˜ï¼‰
logger.warning("æ•°æ®ç‚¹ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")

# ERROR: é”™è¯¯ä¿¡æ¯ï¼ˆéœ€è¦å…³æ³¨ä½†ä¸å½±å“ç³»ç»Ÿè¿è¡Œï¼‰
logger.error(f"è¯»å–æ•°æ®å¤±è´¥: {e}", exc_info=True)

# CRITICAL: ä¸¥é‡é”™è¯¯ï¼ˆå¯èƒ½å¯¼è‡´ç³»ç»Ÿåœæ­¢ï¼‰
logger.critical(f"æ•°æ®åº“è¿æ¥å®Œå…¨å¤±è´¥: {e}")
```

---

## 9. é™„å½•ï¼šé…ç½®æ–‡ä»¶è¯´æ˜

### 9.1 é…ç½®æ–‡ä»¶åˆ—è¡¨

| é…ç½®æ–‡ä»¶ | è®¿é—®æ–¹å¼ | ç”¨é€” |
|---------|---------|------|
| `main_config.yaml` | `ctx.main_config` | çº¿ç¨‹å‚æ•°ã€å…³é—­è¶…æ—¶ç­‰ |
| `uid_config.yaml` | `ctx.uid_config` | æ•°æ®ä¸­å¿ƒæ¶æ„å’ŒUIDæ˜ å°„ |
| `models_config.yaml` | `ctx.models_config` | é¢„æµ‹æ¨¡å‹ã€ä¼˜åŒ–æ¨¡å‹å‚æ•° |
| `modules_config.yaml` | `ctx.modules_config` | å„æ¨¡å—çš„è¿è¡Œå‚æ•° |
| `security_boundary_config.yaml` | `ctx.security_boundary_config` | æ§åˆ¶èŒƒå›´ã€çº¦æŸæ¡ä»¶ |
| `utils_config.yaml` | `ctx.utils_config` | æ—¥å¿—ã€InfluxDBè¿æ¥é…ç½® |
| `influxdb_read_write_config.yaml` | `ctx.influxdb_read_write_config` | æ•°æ®è¯»å†™ç­–ç•¥ |

### 9.2 å¸¸ç”¨é…ç½®è®¿é—®ç¤ºä¾‹

```python
# è·å–çº¿ç¨‹é…ç½®
thread_config = ctx.main_config.get("threads", {}).get("prediction_training", {})
interval = thread_config.get("interval", 3600)
mode = thread_config.get("mode", "fixed_interval")

# è·å–æ¨¡å‹å‚æ•°
model_params = ctx.models_config.get("prediction_model", {})
hidden_dim = model_params.get("hidden_dim", 64)
learning_rate = model_params.get("learning_rate", 0.001)

# è·å–å®‰å…¨è¾¹ç•Œ
boundaries = ctx.security_boundary_config.get("temperature", {})
max_temp = boundaries.get("max", 27.0)
min_temp = boundaries.get("min", 18.0)

# è·å–æ¨¡å—é…ç½®
prediction_config = ctx.modules_config.get("prediction", {})
preprocessing_config = prediction_config.get("preprocessing", {})
```

### 9.3 è¯»å†™é…ç½®è¯¦è§£ï¼ˆinfluxdb_read_write_config.yamlï¼‰

#### è¯»å–é…ç½®ç»“æ„

```yaml
read:
  default:           # å…¨å±€é»˜è®¤é…ç½®
    mode: "time_range"
    time_range:
      duration: 1
      unit: "h"

  dc_status_data_client:           # å®¢æˆ·ç«¯é…ç½®
    datacenter_latest_status:       # é…ç½®é¡¹
      read_method: "read_all_observable_data"
```

#### å†™å…¥é…ç½®ç»“æ„

```yaml
write:
  default:           # å…¨å±€é»˜è®¤é…ç½®
    batch_size: 100
    retry_times: 3

  prediction_data_client:          # å®¢æˆ·ç«¯é…ç½®
    prediction_by_uid:              # é…ç½®é¡¹
      write_mode: "separate_by_uid"
      measurement_template: "{uid}"
      tag_set:
        horizon: "{horizon}"
      field_set:
        value: "{value}"
```

---

## 10. å¿«é€Ÿå‚è€ƒå¡ç‰‡

### æ•°æ®è¯»å–

```python
data = ctx.data_reader.read_influxdb_data(client_key, config_key)
# è¿”å›: Dict[str, pd.DataFrame]
```

### æ•°æ®å†™å…¥

```python
success = ctx.data_writer.write_influxdb_data(client_key, config_key, data, **kwargs)
# è¿”å›: bool
```

### å…³é”®æ“ä½œä¿æŠ¤

```python
from utils.critical_operation import critical_operation

with critical_operation(ctx):
    # å—ä¿æŠ¤çš„æ“ä½œï¼ˆå¦‚ä¿å­˜æ¨¡å‹ï¼‰
    model.save("model.pth")
```

### é€€å‡ºä¿¡å·æ£€æŸ¥

```python
# å¾ªç¯æ¡ä»¶
while not ctx.shutdown_event.is_set():
    ...

# ç­‰å¾…ï¼ˆæ›¿ä»£ time.sleepï¼‰
if ctx.shutdown_event.wait(timeout=60):
    break  # æ”¶åˆ°é€€å‡ºä¿¡å·
```

### æ—¥å¿—è®°å½•

```python
logger = ctx.loggers["prediction_training"]
logger.info("æ­£å¸¸ä¿¡æ¯")
logger.warning("è­¦å‘Šä¿¡æ¯")
logger.error("é”™è¯¯ä¿¡æ¯", exc_info=True)
```

---

> ğŸ“ **æ–‡æ¡£ç»´æŠ¤**: å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»é¡¹ç›®è´Ÿè´£äºº
>
> ğŸ”— **ç›¸å…³èµ„æº**:
> - é¡¹ç›®ä»£ç : `DC_Energy_conservation/main.py`
> - é…ç½®æ–‡ä»¶: `configs/` ç›®å½•
> - æµ‹è¯•ç”¨ä¾‹: `augment_test/` ç›®å½•

